{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T05:48:39.552279Z",
     "start_time": "2020-01-03T05:48:39.549711Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2,os,glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T05:48:40.098482Z",
     "start_time": "2020-01-03T05:48:40.076541Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/gicsd_labels.csv\")\n",
    "\n",
    "# removing spaces for easy usage\n",
    "data.columns = ['IMAGE_FILENAME', 'LABEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:33:36.765290Z",
     "start_time": "2019-12-23T16:33:36.741052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " FULL_VISIBILITY        646\n",
       " PARTIAL_VISIBILITY     123\n",
       " NO_VISIBILITY           31\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.LABEL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:33:37.293606Z",
     "start_time": "2019-12-23T16:33:37.286561Z"
    }
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"data/images/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seggregating images to different folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:33:40.871694Z",
     "start_time": "2019-12-23T16:33:40.868991Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.set_index('IMAGE_FILENAME',drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:33:41.736385Z",
     "start_time": "2019-12-23T16:33:41.732275Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs('keras_data/FULL_VISIBILITY',exist_ok=True)\n",
    "os.makedirs('keras_data/PARTIAL_VISIBILITY',exist_ok=True)\n",
    "os.makedirs('keras_data/NO_VISIBILITY',exist_ok=True)\n",
    "for f in files:\n",
    "    filename = os.path.basename(f)\n",
    "    label = data.loc[filename]['LABEL'].strip()\n",
    "    os.rename(f,'keras_data/'+label+'/'+filename)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying to denoise image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:34:19.626173Z",
     "start_time": "2019-12-23T16:34:19.616173Z"
    }
   },
   "outputs": [],
   "source": [
    "im = cv2.imread('keras_data/FULL_VISIBILITY/GICSD_10_0_13.png')\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(im,None,10,10,7,21)\n",
    "\n",
    "\n",
    "op =np.concatenate((im,dst),axis=1)\n",
    "cv2.imshow(\"preview\",op)\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using sift features for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T05:49:03.798999Z",
     "start_time": "2020-01-03T05:49:03.795132Z"
    }
   },
   "outputs": [],
   "source": [
    "data.LABEL = pd.Categorical(data.LABEL)\n",
    "labels = data.LABEL.cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T19:21:06.232533Z",
     "start_time": "2019-12-23T19:21:06.200177Z"
    }
   },
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "features = []\n",
    "for row in data.iterrows():\n",
    "    img = cv2.imread('data/images/'+row[0])\n",
    "    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    kp = sift.detect(gray,None)\n",
    "    features.append(kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T19:21:06.232533Z",
     "start_time": "2019-12-23T19:21:06.200177Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modeling(keras models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T09:35:41.149377Z",
     "start_time": "2019-12-23T09:35:39.937111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras_preprocessing.image import image_data_generator\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T09:45:17.277028Z",
     "start_time": "2019-12-23T09:45:17.273303Z"
    }
   },
   "outputs": [],
   "source": [
    "### preprocessing function\n",
    "### this can be used to preprocess color images to gray\n",
    " cnvt2gray = lambda x : cv2.cvtColor(x,cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T09:35:51.594507Z",
     "start_time": "2019-12-23T09:35:42.190916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/prateek/.virtualenvs/cv_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/prateek/.virtualenvs/cv_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateek/.virtualenvs/cv_p36/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "train_datagen = image_data_generator.ImageDataGenerator(horizontal_flip=True,vertical_flip=True,shear_range=.5\\\n",
    "                                                        ,rotation_range=30,validation_split=.3)#,preprocessing_function=cnvt2gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:25:33.665379Z",
     "start_time": "2019-12-21T09:25:33.445809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 562 images belonging to 3 classes.\n",
      "Found 238 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"keras_data/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset = \"training\"\n",
    ")\n",
    "validation = train_datagen.flow_from_directory(\n",
    "    directory=\"keras_data/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset = \"validation\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:25:33.730230Z",
     "start_time": "2019-12-21T09:25:33.667208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1_pad\n",
      "2 conv1\n",
      "3 bn_conv1\n",
      "4 activation_1\n",
      "5 pool1_pad\n",
      "6 max_pooling2d_1\n",
      "7 res2a_branch2a\n",
      "8 bn2a_branch2a\n",
      "9 activation_2\n",
      "10 res2a_branch2b\n",
      "11 bn2a_branch2b\n",
      "12 activation_3\n",
      "13 res2a_branch2c\n",
      "14 res2a_branch1\n",
      "15 bn2a_branch2c\n",
      "16 bn2a_branch1\n",
      "17 add_1\n",
      "18 activation_4\n",
      "19 res2b_branch2a\n",
      "20 bn2b_branch2a\n",
      "21 activation_5\n",
      "22 res2b_branch2b\n",
      "23 bn2b_branch2b\n",
      "24 activation_6\n",
      "25 res2b_branch2c\n",
      "26 bn2b_branch2c\n",
      "27 add_2\n",
      "28 activation_7\n",
      "29 res2c_branch2a\n",
      "30 bn2c_branch2a\n",
      "31 activation_8\n",
      "32 res2c_branch2b\n",
      "33 bn2c_branch2b\n",
      "34 activation_9\n",
      "35 res2c_branch2c\n",
      "36 bn2c_branch2c\n",
      "37 add_3\n",
      "38 activation_10\n",
      "39 res3a_branch2a\n",
      "40 bn3a_branch2a\n",
      "41 activation_11\n",
      "42 res3a_branch2b\n",
      "43 bn3a_branch2b\n",
      "44 activation_12\n",
      "45 res3a_branch2c\n",
      "46 res3a_branch1\n",
      "47 bn3a_branch2c\n",
      "48 bn3a_branch1\n",
      "49 add_4\n",
      "50 activation_13\n",
      "51 res3b_branch2a\n",
      "52 bn3b_branch2a\n",
      "53 activation_14\n",
      "54 res3b_branch2b\n",
      "55 bn3b_branch2b\n",
      "56 activation_15\n",
      "57 res3b_branch2c\n",
      "58 bn3b_branch2c\n",
      "59 add_5\n",
      "60 activation_16\n",
      "61 res3c_branch2a\n",
      "62 bn3c_branch2a\n",
      "63 activation_17\n",
      "64 res3c_branch2b\n",
      "65 bn3c_branch2b\n",
      "66 activation_18\n",
      "67 res3c_branch2c\n",
      "68 bn3c_branch2c\n",
      "69 add_6\n",
      "70 activation_19\n",
      "71 res3d_branch2a\n",
      "72 bn3d_branch2a\n",
      "73 activation_20\n",
      "74 res3d_branch2b\n",
      "75 bn3d_branch2b\n",
      "76 activation_21\n",
      "77 res3d_branch2c\n",
      "78 bn3d_branch2c\n",
      "79 add_7\n",
      "80 activation_22\n",
      "81 res4a_branch2a\n",
      "82 bn4a_branch2a\n",
      "83 activation_23\n",
      "84 res4a_branch2b\n",
      "85 bn4a_branch2b\n",
      "86 activation_24\n",
      "87 res4a_branch2c\n",
      "88 res4a_branch1\n",
      "89 bn4a_branch2c\n",
      "90 bn4a_branch1\n",
      "91 add_8\n",
      "92 activation_25\n",
      "93 res4b_branch2a\n",
      "94 bn4b_branch2a\n",
      "95 activation_26\n",
      "96 res4b_branch2b\n",
      "97 bn4b_branch2b\n",
      "98 activation_27\n",
      "99 res4b_branch2c\n",
      "100 bn4b_branch2c\n",
      "101 add_9\n",
      "102 activation_28\n",
      "103 res4c_branch2a\n",
      "104 bn4c_branch2a\n",
      "105 activation_29\n",
      "106 res4c_branch2b\n",
      "107 bn4c_branch2b\n",
      "108 activation_30\n",
      "109 res4c_branch2c\n",
      "110 bn4c_branch2c\n",
      "111 add_10\n",
      "112 activation_31\n",
      "113 res4d_branch2a\n",
      "114 bn4d_branch2a\n",
      "115 activation_32\n",
      "116 res4d_branch2b\n",
      "117 bn4d_branch2b\n",
      "118 activation_33\n",
      "119 res4d_branch2c\n",
      "120 bn4d_branch2c\n",
      "121 add_11\n",
      "122 activation_34\n",
      "123 res4e_branch2a\n",
      "124 bn4e_branch2a\n",
      "125 activation_35\n",
      "126 res4e_branch2b\n",
      "127 bn4e_branch2b\n",
      "128 activation_36\n",
      "129 res4e_branch2c\n",
      "130 bn4e_branch2c\n",
      "131 add_12\n",
      "132 activation_37\n",
      "133 res4f_branch2a\n",
      "134 bn4f_branch2a\n",
      "135 activation_38\n",
      "136 res4f_branch2b\n",
      "137 bn4f_branch2b\n",
      "138 activation_39\n",
      "139 res4f_branch2c\n",
      "140 bn4f_branch2c\n",
      "141 add_13\n",
      "142 activation_40\n",
      "143 res5a_branch2a\n",
      "144 bn5a_branch2a\n",
      "145 activation_41\n",
      "146 res5a_branch2b\n",
      "147 bn5a_branch2b\n",
      "148 activation_42\n",
      "149 res5a_branch2c\n",
      "150 res5a_branch1\n",
      "151 bn5a_branch2c\n",
      "152 bn5a_branch1\n",
      "153 add_14\n",
      "154 activation_43\n",
      "155 res5b_branch2a\n",
      "156 bn5b_branch2a\n",
      "157 activation_44\n",
      "158 res5b_branch2b\n",
      "159 bn5b_branch2b\n",
      "160 activation_45\n",
      "161 res5b_branch2c\n",
      "162 bn5b_branch2c\n",
      "163 add_15\n",
      "164 activation_46\n",
      "165 res5c_branch2a\n",
      "166 bn5c_branch2a\n",
      "167 activation_47\n",
      "168 res5c_branch2b\n",
      "169 bn5c_branch2b\n",
      "170 activation_48\n",
      "171 res5c_branch2c\n",
      "172 bn5c_branch2c\n",
      "173 add_16\n",
      "174 activation_49\n"
     ]
    }
   ],
   "source": [
    "# add a global spatial average pooling layer\n",
    "# create the base pre-trained model\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "# and a logistic layer -- let's say we have 3 classes\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "    # this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:25:33.800525Z",
     "start_time": "2019-12-21T09:25:33.794795Z"
    }
   },
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:161]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[161:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:25:34.148310Z",
     "start_time": "2019-12-21T09:25:33.998935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘snapshots’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:25:34.997447Z",
     "start_time": "2019-12-21T09:25:34.932814Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "# parallel_model = multi_gpu_model(model, gpus=3)\n",
    "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:46:21.693883Z",
     "start_time": "2019-12-21T09:25:35.145168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.6226 - accuracy: 0.7822 - val_loss: 0.8684 - val_accuracy: 0.8109\n",
      "WARNING:tensorflow:From /home/prateek/.virtualenvs/cv_p36/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 60s 2s/step - loss: 0.4701 - accuracy: 0.8144 - val_loss: 1.0159 - val_accuracy: 0.8109\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 60s 2s/step - loss: 0.4525 - accuracy: 0.8133 - val_loss: 0.7752 - val_accuracy: 0.8109\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.3822 - accuracy: 0.8277 - val_loss: 0.5118 - val_accuracy: 0.8109\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 60s 2s/step - loss: 0.4124 - accuracy: 0.8251 - val_loss: 0.1261 - val_accuracy: 0.7605\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 60s 2s/step - loss: 0.3532 - accuracy: 0.8412 - val_loss: 0.8118 - val_accuracy: 0.4286\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.3726 - accuracy: 0.8499 - val_loss: 0.4281 - val_accuracy: 0.8067\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.3222 - accuracy: 0.8562 - val_loss: 0.6981 - val_accuracy: 0.8193\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.3190 - accuracy: 0.8648 - val_loss: 0.9993 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.2907 - accuracy: 0.8863 - val_loss: 0.6788 - val_accuracy: 0.6765\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.2915 - accuracy: 0.8755 - val_loss: 1.7876 - val_accuracy: 0.7815\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.2738 - accuracy: 0.8805 - val_loss: 0.3985 - val_accuracy: 0.7563\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.2337 - accuracy: 0.8927 - val_loss: 0.3836 - val_accuracy: 0.6176\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.2376 - accuracy: 0.9049 - val_loss: 0.1063 - val_accuracy: 0.7731\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.2298 - accuracy: 0.9056 - val_loss: 0.4325 - val_accuracy: 0.7815\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.2208 - accuracy: 0.9227 - val_loss: 0.4163 - val_accuracy: 0.7521\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.2114 - accuracy: 0.9165 - val_loss: 0.5235 - val_accuracy: 0.7899\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.1956 - accuracy: 0.9131 - val_loss: 1.3473 - val_accuracy: 0.8151\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.1612 - accuracy: 0.9410 - val_loss: 0.0198 - val_accuracy: 0.8067\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.1858 - accuracy: 0.9217 - val_loss: 0.5365 - val_accuracy: 0.8109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f109bfadfd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "checkpoints = [ModelCheckpoint(\"snapshots/checkpoint-{epoch}.h5\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1),tensorboard_callback ]\n",
    "\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(train_generator,epochs=20,steps_per_epoch=30,validation_data=validation,shuffle=True,callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_p36",
   "language": "python",
   "name": "cv_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
